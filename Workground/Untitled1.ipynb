{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Recognition with Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teodor Kanev and Georgi Dimitrov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Face recognition is a method of identifying or verifying the identity of an individual from a digital image.\n",
    "Our task for this project is to identify the exact position of the person face."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data source and preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://lh3.googleusercontent.com/proxy/IFXjMln-UJ5JieNBR_vyHhUbzsT4dWJqHeqhvTXq0u3duGSTTTs8ezMUcyvLA9kzl4ug6pnMBfY-zJTEPdhzLpEp4T5P7zFIxlDAnRs\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset we use can be found using the official website: http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html.\n",
    "\n",
    "CelebFaces Attributes Dataset (CelebA) is a large-scale face attributes dataset with <b>202,599</b> celebrity images. For every image, we have 4 values (X-coordinate of top left corner, Y-coordinate of top left corner, width and height of the box) describing a rectangle covering the face."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, let's import some libraries and write help functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib.patches as patches\n",
    "import numpy as np\n",
    "from skimage import color\n",
    "from skimage import io\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_index(name):\n",
    "    return int(name[:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_name(index):\n",
    "    name = ''\n",
    "    for i in range(6 - len(str(index))):\n",
    "        name += '0'\n",
    "    name = name + str(index) + '.jpg'\n",
    "    return name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next function extracts all images located in given folder to <b>images</b> with size 64x64 and the original\n",
    "size is stored in <b>sizes</b>. Every item in <b>images</b> is with shape (64,64,3) using that every image is\n",
    "in rgb format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_rgb_images_from_folder(folder):\n",
    "    images = {}\n",
    "    sizes = {}\n",
    "    for filename in os.listdir(folder):\n",
    "        img = Image.open(os.path.join(folder,filename))\n",
    "        if img is not None: \n",
    "            sizes[to_index(filename)] = img.size  \n",
    "            new_img = img.resize((64,64), Image.ANTIALIAS)\n",
    "            images[to_index(filename)] = new_img \n",
    "    return images, sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we resize every image, we need to resize the bounding boxes aswell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_bbox(name, old_w, old_h, df):\n",
    "    df.at[to_index(name)-1, 'x_1'] *= (64/old_w)\n",
    "    df.at[to_index(name)-1, 'y_1'] *= (64/old_h)\n",
    "    df.at[to_index(name)-1, 'width'] *= (64/old_w)\n",
    "    df.at[to_index(name)-1, 'height'] *= (64/old_h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving all images in <b>train_imgs</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_name = 'Data/Part 1'\n",
    "train_imgs, old_sizes = load_rgb_images_from_folder(folder_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Order them by image name in ordered dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "od = collections.OrderedDict(sorted(train_imgs.items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save bounding boxes(which are sorted by image name) in data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Data/list_bbox_celeba.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale bounding boxes for every image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in od.keys():\n",
    "    img_number = i\n",
    "    change_bbox(to_name(img_number), old_sizes[img_number][0], old_sizes[img_number][1], df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert images to numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst = []\n",
    "for i in range(1,40000):\n",
    "    tst.append(np.array(od[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use only needed bounding boxes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(df.head(39999).drop(columns = ['image_id'], axis = 1))[:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shuffle images and bounding boxes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "images_shuffled, labels_shuffled = shuffle(tst, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the dataset into: <br>\n",
    "    <b> - Train data</b> - 80%<br>\n",
    "    <b> - Validation data</b> - 10%<br>\n",
    "    <b> - Test data</b> - 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    images_shuffled, labels_shuffled, test_size=0.2, random_state=7)\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_val, y_val, test_size = 0.5, random_state = 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert everything to numpyp array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)\n",
    "Y_train = np.array(y_train)\n",
    "X_val = np.array(X_val) \n",
    "Y_val = np.array(y_val)\n",
    "X_test = np.array(X_test)\n",
    "Y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import tensorflow libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.Input(shape=(64, 64, 3)))\n",
    "model.add(layers.Conv2D(64, kernel_size=(9, 9), strides=(1, 1), padding=\"same\", activation = \"relu\"))\n",
    "\n",
    "model.add(layers.BatchNormalization())\n",
    "\n",
    "model.add(layers.Conv2D(64, kernel_size=(2, 2), strides=(2, 2), padding=\"same\", activation = \"relu\"))\n",
    "model.add(layers.Conv2D(64, kernel_size=(3, 3), strides=(1, 1), padding=\"same\", activation = \"relu\"))\n",
    "model.add(layers.BatchNormalization())\n",
    "\n",
    "model.add(layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding=\"valid\"))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(256))\n",
    "model.add(layers.PReLU())\n",
    "model.add(layers.Dense(4))\n",
    "\n",
    "model.summary()\n",
    "model.compile('Nadam', loss=tf.keras.losses.Huber())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, Y_train, epochs=10, validation_data=(X_val, Y_val), verbose=1, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for Intersection over Union metric to determine the model corectness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IOU(bbox1, bbox2):\n",
    "    x1, y1, w1, h1 = bbox1[0], bbox1[1], bbox1[2], bbox1[3]\n",
    "    x2, y2, w2, h2 = bbox2[0], bbox2[1], bbox2[2], bbox2[3]\n",
    "\n",
    "    w_I = min(x1 + w1, x2 + w2) - max(x1, x2)\n",
    "    h_I = min(y1 + h1, y2 + h2) - max(y1, y2)\n",
    "    if w_I <= 0 or h_I <= 0:  # no overlap\n",
    "        return 0.\n",
    "    I = w_I * h_I\n",
    "\n",
    "    U = w1 * h1 + w2 * h2 - I\n",
    "\n",
    "    return I / U"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to calculate overall accuracy of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy(y_pred, y_test):\n",
    "    tmp = []\n",
    "    for i in range(len(y_pred)):\n",
    "        tmp.append(IOU(y_pred[i], y_test[i]))\n",
    "    \n",
    "    return np.average(tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_accuracy(y_pred, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to draw prediction bounding box on the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_bbox(img, bbox):\n",
    "\n",
    "    fig,ax = plt.subplots(1)\n",
    "\n",
    "    # Display the image\n",
    "    ax.imshow(img)\n",
    "\n",
    "    # Create a Rectangle patch\n",
    "    rect = patches.Rectangle((bbox[0],bbox[1]),bbox[2],bbox[3],linewidth=1,edgecolor='r',facecolor='none')\n",
    "\n",
    "    # Add the patch to the Axes\n",
    "    ax.add_patch(rect)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_bbox[X_test[7], y_pred[7]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_bbox[X_test[17], y_pred[17]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_bbox[X_test[27], y_pred[27]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see where we fail to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for i in range(1,500):\n",
    "    results.append([IOU(Y_test[i], y_pred[i]),i])\n",
    "results.sort()\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_bbox(X_test[481], y_pred[481])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_bbox(X_test[5], y_pred[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_bbox(X_test[106], y_pred[106])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_bbox(X_test[19], y_pred[19])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
